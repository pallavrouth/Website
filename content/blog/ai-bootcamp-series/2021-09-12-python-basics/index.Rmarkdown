---
title: 'Advanced Pandas'
subtitle: "Dplyr style coding in Pandas"
excerpt: "Using Pandas to chain operations"
author: Pallav Routh
date: '2021-09-12'
slug: 
  - python-advanced
categories:
  - Python
tags:
  - Coding
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
```

In this blog post, I demonstrate how to replicate `dplyr` style data manipulation in `pandas`. A characteristic feature of `dplyr` is its ability to chain together multiple operations using the infamous `%>%` operator. I will show `dplyr` and `pandas` code side by side which will further highlight similarities and differences between the two packages. Hopefully, this helps users migrate from `dplyr` to `pandas`.   

## Loading pandas and dplyr

```{python}
import pandas as pd
import numpy as np
```

```{r}
suppressPackageStartupMessages(library(dplyr))
```


## Data

We are going to use the popular `cigarettes` dataset. Let's read in the data set.

```{python}
data = pd.read_csv('https://raw.githubusercontent.com/pallavrouth/AI-Bootcamp/main/Data/cigarettes.csv', index_col = 'Unnamed: 0')
```

Here is quick overview -

```{r}
glimpse(py$data)
```

## Chaining in pandas

To demonstrate chaining in pandas, lets perform the following operation on the dataset : select 3 columns and filter rows corresponding to certain states. 

In R:

```{r}
py$data %>% 
  select(state,year,population) %>% 
  filter(state %in% c('AL','AZ','VT')) %>% 
  head(.,5)
```

In python:

```{python}
(
  data
    .loc[:,['state','year','population']] 
    .loc[lambda d : d.state.isin(['AL','AZ','VT'])] 
    .head()
)
```

In python, you need to do two things to employ chaining : (1) use a parenthesis to enclose the set of operations and (2) use the '.' symbol at the end of each operation as a replacement for `%>%`. 

Now, lets look at some common set of operations in `dplyr`.

## Select, filter and sort

The first advanced operation is selecting columns following by filtering some rows followed by sorting. The sequence may not be same in all scenarios. 

In R:

```{r}
py$data %>% 
  select(state,year,population) %>% 
  filter(state %in% c('AL','AZ','VT') & population > 10e3) %>% 
  arrange(population) %>% 
  head(.,5)
```

In python:

```{python}
(data
  .loc[:,['state','year','population']] 
  .loc[lambda d : (d.state.isin(['AL','AZ','VT'])) & (d.population > 10e3)] 
  .sort_values(['population'])
  .head()) 
```

For multiple selections, I prefer using `query` instead of `loc`.

```{python}
(data
  .loc[:,['state','year','population']] 
  .query('(population > 10e3) and (state in ["AL","AZ","VT"])') 
  .sort_values(['population'])
  .head())
```


## Mutate, groupby and summarize

Another common advanced operation is mutate, groupby and then summarize. In this type of operation, you want to first create some column and then summarize that column within each group. Let's groupby and find maximum within each group.

In R: 

```{r}
py$data %>% 
  mutate(population_1000 = population / 1000) %>% 
  group_by(state) %>% 
    summarize(max(population_1000)) %>% 
  ungroup() %>% 
  head(.,5)
```

In python:

```{python}
(data[['state','year','population']] # <-- select
  .assign(population_1000 = lambda d : d.population / 1000) # <-- mutate
  .groupby('state') 
    .population_1000 
    .max()
  .head())
```

Using `aggregate` function instead of `max`. 

```{python}
(data[['state','year','population','packs']]
  .assign(population_1000 = lambda d: d.population / 1000)
  .groupby('state')
    .aggregate({'population_1000':'max'})
  .head())
```

## Groupby and mutate

Another advanced operation is groupby followed by mutate. In this type of operations, you want to apply some operation with every group. 

In R:

```{r}
py$data %>% 
  select(state,year,population,packs) %>% 
  mutate(population_1000 = population / 1000) %>% 
  group_by(state) %>% 
    mutate(mean_packs = mean(packs)) %>% 
  ungroup() %>% 
  head(.,5)
```

In python:

```{python}
(data[['state','year','population','packs']]
  .assign(population_1000 = lambda d : d.population / 1000,
          mean_packs = lambda d : d.groupby('state')  
                                      .packs 
                                      .transform(lambda x : x.mean()))
  .head())
```

Alternatively,

```{python}
(data[['state','year','population','packs']]
  .assign(population_1000 = lambda d : d.population / 1000,
          mean_packs = lambda d : d.groupby('state')[['packs']]
                                      .transform(lambda x : x.mean()))
  .head())
```

## Conditional mutate - ifelse

Another common type of advanced operation is conditional mutate. Here you want to create a column based on a condition that applies to another column(s).

In R:

```{r}
py$data %>% 
  select(state,year,population,packs) %>% 
  mutate(population_1000 = population / 1000,
         ifelsecol = ifelse(packs > 120,"> 120","< 120")) %>% 
  head(.,5)
```


In python:

```{python}
(data[['state','year','population','packs']]
  .assign(population_1000 = lambda d : d.population / 1000,
          ifelsecol = lambda d : np.where(d.packs > 120, "> 120","< 120"))
  .head())
```

In my humble opinion, I think `dplyr` syntax is way more intuitive than `pandas`.

## Multiple mutate

Sometimes, one needs to apply the same mutating function to multiple columns. Its rather cumbersome to repeat the same operation individually to every column. 

In R:

```{r}
py$data %>% 
  select(population,packs,income,tax) %>%
  mutate(across(population:tax,~log(. + 1),.names = "log_{col}"))
```

In python:

```{python}
(data
  .assign(population_1000 = lambda d : d.population / 1000,
          ifelsecol = lambda d : np.where(d.packs > 120, "> 120","< 120"))
  .head())
```

